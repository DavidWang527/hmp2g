{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko, os\n",
    "\n",
    "class MySFTPClient(paramiko.SFTPClient):\n",
    "    def put_dir(self, source, target):\n",
    "        ''' Uploads the contents of the source directory to the target path. The\n",
    "            target directory needs to exists. All subdirectories in source are \n",
    "            created under target.\n",
    "        '''\n",
    "        for item in os.listdir(source):\n",
    "            if os.path.isfile(os.path.join(source, item)):\n",
    "                # print(os.path.join(source, item))\n",
    "                self.put(os.path.join(source, item), '%s/%s' % (target, item))\n",
    "            else:\n",
    "                # print('mkdir:', '%s/%s' % (target, item))\n",
    "                self.mkdir('%s/%s' % (target, item), ignore_existing=True)\n",
    "                self.put_dir(os.path.join(source, item), '%s/%s' % (target, item))\n",
    "\n",
    "    def mkdir(self, path, mode=511, ignore_existing=False):\n",
    "        ''' Augments mkdir by adding an option to not fail if the folder exists  '''\n",
    "        try:\n",
    "            super(MySFTPClient, self).mkdir(path, mode)\n",
    "            # print('make dir', path)\n",
    "        except IOError as e:\n",
    "            # print(path,e)\n",
    "            if ignore_existing:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "def upload_experiment_results():\n",
    "    path =\n",
    "    name = \n",
    "    try:\n",
    "        from UTILS.keys import KEY\n",
    "        addr = KEY.addr\n",
    "        usr = KEY.usr\n",
    "        pwd = KEY.pwd\n",
    "    except:\n",
    "        print('No data center is configured 没有配置中央服务器')\n",
    "        return\n",
    "\n",
    "    ssh = paramiko.SSHClient() \n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh.load_host_keys(os.path.expanduser(os.path.join(\"~\", \".ssh\", \"known_hosts\")))\n",
    "    ssh.connect(addr, username=usr, password=pwd)\n",
    "    sftp = MySFTPClient.from_transport(ssh.get_transport())\n",
    "    sftp.mkdir('/home/fuqingxu/paramikotest/', ignore_existing=True)\n",
    "    sftp.mkdir('/home/fuqingxu/paramikotest/%s'%name, ignore_existing=True)\n",
    "    sftp.put_dir(path, '/home/fuqingxu/paramikotest/%s'%name)\n",
    "    sftp.close()\n",
    "\n",
    "upload_experiment_results(\"./ZHECKPOINT/HistoryRollingSep(40itf) r1/\", name=\"HistoryRollingSep(40itf) r1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.05 ms ± 3.93 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from UTILS.tensor_ops import my_view, __hash__, objload\n",
    "\n",
    "obs_feed_new, prev_obs_feed, valid_mask, N_valid, next_his_pool = objload()\n",
    "__hash__(roll_hisory(obs_feed_new, prev_obs_feed, valid_mask, N_valid, next_his_pool))\n",
    "%timeit roll_hisory(obs_feed_new, prev_obs_feed, valid_mask, N_valid, next_his_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timestep = reward_logits.shape[0]\n",
    "n_agent = reward_logits.shape[1]\n",
    "assert not ((reward != 0) & (reward!=1) & (reward!=-0.5) & (reward!=0.5)).any()\n",
    "# {-0.5, 0, 0.5, 1} -> {3<(-1), 0, 1, 2}\n",
    "reward_projection = lambda r: np.where(r<0, 3, r*2).astype(np.int)\n",
    "# apply projection\n",
    "reward_class = reward_projection(reward) # np_one_hot(,4)\n",
    "# ($time_step.$n_agent.) -> ($time_step.$n_agent_.$n_agent.)\n",
    "reward_class = np_repeat_at(reward_class, insert_dim=1, n_times=n_agent)\n",
    "# not zero reward\n",
    "not_zero_mask = (reward_class!=0)\n",
    "# reward_class_onehot\n",
    "reward_class_onehot = np_one_hot(reward_class, 4)\n",
    "# reward estimation\n",
    "reward_logits = np_softmax(reward_logits, axis=-1)\n",
    "prediction_rating = np.take_along_axis(reward_logits, axis=-1, \n",
    "    indices=np.expand_dims(reward_class, -1)).squeeze(-1)\n",
    "correct_prediction = (np.argmax(reward_logits, -1) == reward_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshhold = 0.25*1.05\n",
    "eye_mat = np_repeat_at(np.eye(n_agent), insert_dim=0, n_times=n_timestep)\n",
    "compasion_matrix = correct_prediction & (prediction_rating > confidence_threshhold) & not_zero_mask | (eye_mat==1)\n",
    "print(compasion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compasion_matrix = (prediction_rating > confidence_threshhold) & not_zero_mask & (eye_mat==0)\n",
    "compasion_matrix = compasion_matrix.astype(np.int)\n",
    "\n",
    "# 计算分解后的reward，因为reward可能被多个智能体分解\n",
    "n_com = compasion_matrix.sum(-2)\n",
    "assert not (n_com==0).any()\n",
    "reward_decmp = np.where(n_com!=0, reward/n_com, reward) # reward/(n_com+1e-7)\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.matmul.html\n",
    "compassion_reward = np.matmul(compasion_matrix, np.expand_dims(reward_decmp,-1)).squeeze(-1)\n",
    "print(compassion_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "函数说明：在有限的、不均衡的多标签数据集中，按照预设的比例，取出尽可能多的样本\n",
    "'''\n",
    "def sample_balance(x, y, n_class, weight=None):\n",
    "    if weight is None: weight = torch.ones(n_class, device=x.device)\n",
    "    else: weight = torch.Tensor(weight, device=x.device)\n",
    "    n_instance = torch.zeros(n_class, device=x.device)\n",
    "    indices = [None]*n_class\n",
    "    for i in range(n_class):\n",
    "        indices[i] = torch.where(y==i)[0]\n",
    "        n_instance[i] = len(indices[i])\n",
    "    ratio = n_instance/weight\n",
    "    bottle_neck = torch.argmin(n_instance/weight)\n",
    "    r = ratio[bottle_neck]\n",
    "    n_sample = (r*weight).long()\n",
    "    # print(n_instance, n_sample)\n",
    "    new_indices = [indices[i][torch.randperm(n_sample[i])] for i in range(n_class)]\n",
    "    # print(new_indices)\n",
    "    new_indices_ = torch.cat(new_indices)\n",
    "    assert len(new_indices_) == sum(n_sample)\n",
    "    return x[new_indices_], y[new_indices_]\n",
    "\n",
    "'''\n",
    "测试代码\n",
    "'''\n",
    "x = torch.rand(200, 4)\n",
    "y1 = torch.rand(100, 4)\n",
    "y2 = torch.rand(100, 4)\n",
    "y2[:, 0] += 1\n",
    "y = torch.cat((y1,y2))\n",
    "y = torch.argmax(y, -1)\n",
    "print(y)\n",
    "n_class = 4\n",
    "weight = [2,1,1,1]\n",
    "sample_balance(x,y,4,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(100, 4)\n",
    "y = torch.rand(100, 4)\n",
    "y = torch.argmax(y, -1)\n",
    "\n",
    "# return x[new_indices_], y[new_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def my_view(x, shape):\n",
    "    if -1 in shape[1:-1]: return my_view_test(x, shape)\n",
    "    reverse_lookup = True if shape[0] == -1 else False\n",
    "    if not reverse_lookup:\n",
    "        for i, dim in enumerate(shape):\n",
    "            if dim == 0:\n",
    "                shape[i] = x.shape[i]\n",
    "    else:\n",
    "        for i in range(len(shape)):\n",
    "            ni = -(i + 1)  # iter -1,-2,-3,...\n",
    "            dim = shape[ni]\n",
    "            if dim == 0:\n",
    "                shape[ni] = x.shape[ni]\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.reshape(*shape)\n",
    "    return x.view(*shape)\n",
    "\n",
    "def my_view_test(x, shape):\n",
    "    # fill both way until meet -1 \n",
    "    for i, dim in enumerate(shape):\n",
    "        if dim == 0: shape[i] = x.shape[i]\n",
    "        elif dim == -1: break\n",
    "    for i in range(len(shape)):\n",
    "        ni = -(i + 1); dim = shape[ni]\n",
    "        if dim == 0: shape[ni] = x.shape[ni]\n",
    "        elif dim == -1: break\n",
    "    # print(shape)\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.reshape(*shape)\n",
    "    return x.view(*shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "    improve np.reshape and torch.view function\n",
    "    If a dim is assigned with 0, it will keep its original dimension\n",
    "    eg.1    x.shape = (4, 5, 6, 7); new_shape = [0, 0, -1]\n",
    "            y = my_view(x, new_shape)\n",
    "            y.shape = (4, 5, 6*7)\n",
    "\n",
    "    eg.2    x.shape = (4, 5, 6, 7); new_shape = [-1, 0, 0]\n",
    "            y = my_view(x, new_shape)\n",
    "            y.shape = (4*5, 6, 7)\n",
    "\n",
    "(4, 5, 6); new_shape = [0, 0, -1, 3]\n",
    "\n",
    "(4, 5, 6); new_shape = [2, -1, 0, 0]\n",
    "(3, 4, 5, 6); new_shape = [0, 2, -1, 0, 0]\n",
    "\"\"\"\n",
    "\n",
    "my_view(np.zeros(shape=(4, 5, 6)), shape = [2, -1, 0, 0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_view(np.zeros(shape=(4, 5, 6)), shape = [0, 0, -1, 3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "a: cython.int = 0\n",
    "for i in range(10):\n",
    "    a += i\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_method(np.ones(5), np.zeros(5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
