{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0]\n",
      "[0 2 3 1 2 3 3 1 0 0 3 0 2 1 1 1 0 2]\n",
      "[0 5 7 6 2 3 3 6 4 0 7 0 2 1 1 1 4 5]\n",
      "[ 0  5  7  6 10  3 14 13  4  8 15  0  2  1 12  1  9 11]\n",
      "[16  5  7  6 10  3 14 13  4  8 15  0  2 17 12  1  9 11]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def _2div(arr):\n",
    "    arr_res = arr.copy()\n",
    "    arr_pieces = []\n",
    "    pa = 0\n",
    "    st = 0\n",
    "    needdivcnt = 0\n",
    "    for i, a in enumerate(arr):\n",
    "        if a!=pa:\n",
    "            arr_pieces.append([st, i])\n",
    "            if (i-st)!=1: needdivcnt+=1\n",
    "            pa = a\n",
    "            st = i\n",
    "\n",
    "    arr_pieces.append([st, len(arr)])\n",
    "    if (len(arr)-st)!=1: needdivcnt+=1\n",
    "\n",
    "    offset = range(len(arr_pieces), len(arr_pieces)+needdivcnt)\n",
    "    p=0\n",
    "    for arr_p in arr_pieces:\n",
    "        length = arr_p[1] - arr_p[0]\n",
    "        if length == 1: continue\n",
    "        half_len = int(np.ceil(length / 2))\n",
    "        for j in range(arr_p[0]+half_len, arr_p[1]):\n",
    "            try:\n",
    "                arr_res[j] = offset[p]\n",
    "            except:\n",
    "                print('wtf')\n",
    "        p+=1\n",
    "    return arr_res\n",
    "\n",
    "def get_division_tree(n_agents):\n",
    "    agent2divitreeindex = np.arange(n_agents)\n",
    "    np.random.shuffle(agent2divitreeindex)\n",
    "    max_div = np.ceil(np.log2(n_agents)).astype(int)\n",
    "    levels = np.zeros(shape=(max_div+1, n_agents), dtype=int)\n",
    "    for ith, level in enumerate(levels):\n",
    "        if ith == 0: continue\n",
    "        res = _2div(levels[ith-1,:])\n",
    "        levels[ith,:] = res\n",
    "    res_levels = levels.copy()\n",
    "    for i, div_tree_index in enumerate(agent2divitreeindex):\n",
    "        res_levels[:, i] = levels[:, div_tree_index]\n",
    "    return res_levels\n",
    "\n",
    "\n",
    "res = get_division_tree(18)\n",
    "for r in res:\n",
    "    print(r)\n",
    "    # print(sorted(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [3, 3] doesn't match the broadcast shape [3, 3, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90860/3818836781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mhit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mp_hit\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_90860/3818836781.py\u001b[0m in \u001b[0;36mrandom_process\u001b[0;34m(probs, hit)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_place\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mprobs\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_place\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [3, 3] doesn't match the broadcast shape [3, 3, 3]"
     ]
    }
   ],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "probs = torch.Tensor([\n",
    "    [0.5, 0.3, 0.2],\n",
    "    [0.1, 0.2, 0.7],\n",
    "    [0.6, 0.2, 0.2],\n",
    "    ])\n",
    "\n",
    "q = [{\n",
    "    0:0, \n",
    "    1:0,\n",
    "    2:0,\n",
    "}]*3\n",
    "yita = p_hit = 0.2\n",
    "\n",
    "\n",
    "def random_process(probs, hit):\n",
    "    with torch.no_grad():\n",
    "        max_place = probs.argmax(-1, keepdims=True)\n",
    "        if hit:\n",
    "            return max_place\n",
    "        else:\n",
    "            # forbit max prob being chosen\n",
    "            pmax = probs.max(axis=-1) #probs[max_place].clone()\n",
    "            p_hat = pmax + (pmax-1)/(1/yita-1)\n",
    "            probs[max_place] = p_hat\n",
    "            k = (1-p_hat)/(1-pmax)\n",
    "            probs *= k\n",
    "            probs[max_place] /= k\n",
    "\n",
    "            # print(probs)\n",
    "            dist = Categorical(probs=probs)\n",
    "            return dist.sample()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(100000):\n",
    "    hit = True if torch.rand(()) < p_hit else False\n",
    "    res = random_process(probs.clone(), hit).item()\n",
    "    q[res] += 1\n",
    "print(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{0: 19905, 1: 30107, 2: 49988}\n",
    "\n",
    "{0: 19946, 1: 29961, 2: 50093}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5696)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client.send_targeted_dgram('ddd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_agent_cluster = torch.Tensor([0.7, 0.2, 0.1])\n",
    "# torch.nn.functional.gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=- 1)\n",
    "q = {0:0,1:0,2:0}\n",
    "for i in range(10000):\n",
    "    torch.set_printoptions(precision=3, sci_mode=False)\n",
    "    t = torch.nn.functional.gumbel_softmax(logits_agent_cluster, tau=0.2).argmax().item()\n",
    "    q[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4670, 1: 2757, 2: 2573}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.464, 0.281, 0.255])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.Tensor([0.7, 0.2, 0.1]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape)\n",
    "    U = U.cuda()\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature=1):\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature=1, hard=False):\n",
    "    \"\"\"\n",
    "    ST-gumple-softmax\n",
    "    input: [*, n_class]\n",
    "    return: flatten --> [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    \n",
    "    if not hard:\n",
    "        return y\n",
    "\n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
    "    y_hard = (y_hard - y).detach() + y\n",
    "    return y_hard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
